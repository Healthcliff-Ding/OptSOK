stages:
  - build_from_scratch
  - format_check
  - build
  - test
  - inference_benchmark
  - sok_benchmark
  - wdl_benchmark
  - dcn_benchmark
  - deepfm_benchmark
  - dlrm_benchmark
  - post_test

.python_format:
  stage: format_check
  tags:
    - nvidia.com/cuda.driver.major=470
  extends:
    - .format:rules:check
  script:
    - pwd
    - ls -all
    - docker pull python:3.8-alpine;
    - docker run -d --rm --name python_${CI_PIPELINE_ID} ${EXTRA_DOCKER_RUN_ARGS} -w /src python:3.8-alpine sleep infinity
    - docker cp $(pwd) python_${CI_PIPELINE_ID}:/src
    - docker exec python_${CI_PIPELINE_ID} sh -c 'pip install black && pwd && ls -all . '
    - docker exec python_${CI_PIPELINE_ID} sh -c "black --line-length 100 --check --diff --color --extend-exclude \"$EXCLUDE\" ./hugectr"
  after_script:
    - docker stop python_${CI_PIPELINE_ID}
  allow_failure: false
  timeout: 15 minutes

.clang_format:
  stage: format_check
  tags:
    - nvidia.com/cuda.driver.major=470
  extends:
    - .format:rules:check
  script:
    - pwd
    - ls -all
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - docker run -d --rm --name clang_${CI_PIPELINE_ID} ${EXTRA_DOCKER_RUN_ARGS} -w /src gitlab-master.nvidia.com:5005/dl/hugectr/hugectr/clang-format-lint-new sleep infinity
    - docker cp $(pwd) clang_${CI_PIPELINE_ID}:/src
    - docker exec clang_${CI_PIPELINE_ID} sh -c "cd ./hugectr && /run-clang-format.py --clang-format-executable /clang-format/$EXECUTABLE -r --exclude $EXCLUDE --style $STYLE --extensions $EXTENSIONS ."
  after_script:
    - docker stop clang_${CI_PIPELINE_ID}
  allow_failure: false
  timeout: 15 minutes

.build_nightly:
  stage: build_from_scratch
  tags:
    - nvidia.com/cuda.driver.major=470
  script:
    - docker login -u "\$oauthtoken" -p "${NVSTAGE_KEY}" "${NVSTAGE_REGISTRY}"
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - if [[ "$MERLIN_REMOTE_REPO" == "" ]]; then
        git clone $REMOTE_REPO;
      else
        git clone $MERLIN_REMOTE_REPO;
      fi
    - if [[ "$OPTIMIZED" == 1 ]]; then
        cd optimized/recommendation/hugectr;
      else
        cd Merlin/docker;
      fi
    - if [[ "$MERLIN_REMOTE_BRANCH" != "" ]]; then
        git checkout $MERLIN_REMOTE_BRANCH;
      fi
    - if [[ "$TEST_NEW_IMAGE" == "1" ]]; then
        DST_IMAGE=${DST_IMAGE}.new_image;
      fi
    - docker build --pull
      -t ${DST_IMAGE}
      -f ${DOCKER_FILE}
      $BUILD_ARGS
      --no-cache 
      . ;
    - docker push ${DST_IMAGE}
  allow_failure: false
  rules:
    - if: $NIGHTLY == "1"
      when: always
    - if: $TEST_NEW_IMAGE == "1"
      when: always
    - when: never
  timeout: 5 hours

# nightly build for sok tf1
.build_nightly_tf1:
  stage: build_from_scratch
  tags:
    - nvidia.com/cuda.driver.major=470
  script:
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - cd tools/dockerfiles
    - docker build --pull
      -t ${DST_IMAGE}
      -f ${DOCKER_FILE}
      $BUILD_ARGS
      --no-cache
      . ;
    - docker push ${DST_IMAGE}
  allow_failure: false
  rules:
    - if: $NIGHTLY == "1"
      when: always
    - if: $TEST_NEW_IMAGE == "1"
      when: always
    - when: never
  timeout: 2 hours

.build:
  stage: build
  tags:
    - nvidia.com/cuda.driver.major=470
  script:
    - export JOB_DOCKERFILE="Dockerfile.${CI_JOB_NAME%%--*}.${CI_PIPELINE_ID}" && echo ${JOB_DOCKERFILE}
    - echo "BUILD_HUGECTR=${BUILD_HUGECTR}"
    - echo "BUILD_HUGECTR2ONNX=${BUILD_HUGECTR2ONNX}"
    - echo "BUILD_SOK=${BUILD_SOK}"
    - echo "BUILD_TF_PLUGIN=${BUILD_TF_PLUGIN}"
    - git submodule update --init --recursive
    - if [[ "$TEST_NEW_IMAGE" == "1" ]]; then
        echo "FROM ${FROM_IMAGE}.new_image" > ${JOB_DOCKERFILE};
      else
        echo "FROM ${FROM_IMAGE}" > ${JOB_DOCKERFILE};
      fi
    - echo "WORKDIR /workdir" >> ${JOB_DOCKERFILE}
    - echo "RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/lib/libcuda.so.1" >> ${JOB_DOCKERFILE}
    - echo "COPY . ." >> ${JOB_DOCKERFILE}
    - if [[ "$BUILD_HUGECTR" == 1 ]]; then
        echo "RUN cd /workdir && mkdir build && cd build && cmake ${CMAKE_OPTION} .. && make -j\$(nproc) && make install" >> ${JOB_DOCKERFILE};
      fi
    - if [[ "$BUILD_SOK" == 1 ]]; then
        echo "RUN cd /workdir/sparse_operation_kit/ && python setup.py install" >> ${JOB_DOCKERFILE};
        echo "RUN pip install nvtx" >> ${JOB_DOCKERFILE};
        echo "ENV LD_LIBRARY_PATH=/usr/local/hugectr/lib:/usr/local/lib:\$LD_LIBRARY_PATH" >> ${JOB_DOCKERFILE};
        echo "ENV LIBRARY_PATH=/usr/local/hugectr/lib:/usr/local/lib:\$LIBRARY_PATH" >> ${JOB_DOCKERFILE};
        echo "ENV PYTHONPATH=/workdir/sparse_operation_kit:\$PYTHONPATH" >> ${JOB_DOCKERFILE};
      fi
    - if [[ "$BUILD_HUGECTR2ONNX" == 1 ]]; then
        echo "RUN cd /workdir/onnx_converter && python3 setup.py install" >> ${JOB_DOCKERFILE};
      fi
    - if [[ "$BUILD_HUGECTR_BACKEND" == 1 ]]; then
        echo "RUN git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/dl/hugectr/hugectr_inference_backend.git hugectr_inference_backend && cd hugectr_inference_backend && git checkout hugectr_performance_test && mkdir build && cd build && cmake -DCMAKE_INSTALL_PREFIX:PATH=/usr/local/hugectr -DTRITON_COMMON_REPO_TAG=$TRITON_BRANCH  -DTRITON_CORE_REPO_TAG=$TRITON_BRANCH -DTRITON_BACKEND_REPO_TAG=$TRITON_BRANCH .. && make -j\$(nproc) && make install && cd ../.. && rm -rfv hugectr_inference_backend" >> ${JOB_DOCKERFILE};
      fi
    - if [[ "$BUILD_TF_PLUGIN" == 1 ]]; then
        echo "RUN pip install ninja" >> ${JOB_DOCKERFILE};
        echo "RUN cd /workdir/hps_tf/ && python setup.py install" >> ${JOB_DOCKERFILE};
      fi
    - echo "RUN rm /usr/local/lib/libcuda.so.1" >> ${JOB_DOCKERFILE};
    - cat ${JOB_DOCKERFILE}
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - if [[ "$TEST_NEW_IMAGE" == "1" ]]; then
        docker pull ${FROM_IMAGE}.new_image;
      else
        docker pull ${FROM_IMAGE};
      fi
    - export DOCKER_CLI_EXPERIMENTAL=enabled;
    - docker buildx create --use --name buildkit_${CI_RUNNER_ID} --node node_${CI_RUNNER_ID} --driver-opt env.BUILDKIT_STEP_LOG_MAX_SIZE=10485760 --driver-opt env.BUILDKIT_STEP_LOG_MAX_SPEED=10485760
    - docker buildx inspect --bootstrap
    - docker buildx build
      --pull
      --push
      -t ${DST_IMAGE}
      -f ${JOB_DOCKERFILE}
      --no-cache .
    - docker stop buildx_buildkit_node_${CI_RUNNER_ID}
    - docker rm buildx_buildkit_node_${CI_RUNNER_ID}
    - docker buildx rm buildkit_${CI_RUNNER_ID}
  allow_failure: false
  rules:
    - if: $CI_PIPELINE_SOURCE =~ /^(push|web|merge_request_event|trigger)$/
      when: always
    - if: $TEST_NEW_IMAGE == "1"
      when: always
    - when: never
  timeout: 5 hours

.build_hugectr:
  extends:
    - .build
    - .hugectr:rules:build

.build_hugectr_daily:
  extends:
    - .build
    - .default:rules:daily-test

.build_sok:
  extends:
    - .build
    - .sok:rules:build

.cluster_test_job:
  extends:
    - .selene_luna_job
    - .hugectr:rules:sanity-test
  allow_failure: false

.cluster_test_job_daily:
  extends:
    - .selene_luna_job
    - .default:rules:daily-test
  allow_failure: false

.dlcluster_test_job:
  extends:
    - .dlcluster_job
    - .hugectr:rules:sanity-test
  allow_failure: false

.dlcluster_test_job_daily:
  extends:
    - .dlcluster_job
    - .default:rules:daily-test
  allow_failure: false

.computelab_test_job_daily:
  extends:
    - .dlcluster_job
    - .default:rules:daily-test
  variables:
    CI_SLURM_PARTITION: "a100-pcie-40gb-product,a100-pcie-80gb-product"
    CI_SLURM_ACCOUNT: "cag"
    WALLTIME:      "02:00:00"
  tags:
  - computelab_generic
  allow_failure: false

.sok_test_job:
  extends:
    - .selene_luna_job
    - .sok:rules:sanity-test
  allow_failure: false

.sok_test_job_daily:
  extends:
    - .selene_luna_job
    - .default:rules:daily-test
  allow_failure: false

.cluster_post_test_job:
  extends:
    - .cluster_test_job
    - .hugectr:rules:sanity-test
  stage: post_test

.cluster_post_test_job_daily:
  extends:
    - .cluster_test_job
    - .default:rules:daily-test
  stage: post_test

.inference_benchmark:
  extends: .selene_luna_job
  stage: inference_benchmark
  before_script:
    - export PARAM=$(echo ${CI_JOB_NAME} | awk -F-- '{print $2}')
    - export BZ=$(echo ${PARAM} | awk -Fx '{print $1}')
    - export MIXED_PRECISION=$(echo ${PARAM} | awk -Fx '{print $2}')
    - export GPFSFOLDER=$LOGDIR/inference_benchmark_${BZ}x${MIXED_PRECISION}
  variables:
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $INFER_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/devtech/hpc-hugectr/inference/dlrm_regression/dlrm/1:/model/dlrm/1,/lustre/fsw/devtech/hpc-hugectr/keynote_inference/perf_data:/perf_data
    SLURM_ACCOUNT: devtech
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/benchmark/inference_benchmark/run.sub
  rules:
    - if: $NIGHTLY == "1"
      when: manual
    - when: never

.sok_benchmark:
  extends: .selene_luna_job
  stage: sok_benchmark
  before_script:
    - export PARAM=$(echo ${CI_JOB_NAME} | awk -F-- '{print $2}')
    - export BZ=$(echo ${PARAM} | awk -Fx '{print $1}')
    - export GPU_NUM=$(echo ${PARAM} | awk -Fx '{print $2}')
    - export GPFSFOLDER=$LOGDIR/sok_benchmark_${BZ}x${GPU_NUM}
  variables:
    GPFSFOLDER: $LOGDIR/sok_benchmark
    CONT: $SOK_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/mlperf/mlperft-dlrm/datasets/terabyte_portion_csv/:/dataset
    SLURM_ACCOUNT: devtech
    WALLTIME: "00:45:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/benchmark/sok/sok_dlrm.sub
  rules:
    - if: $NIGHTLY == "1"
      when: manual
    - when: never

.train_benchmark:
  extends: .selene_luna_job
  before_script:
    - export BENCHMARK=$(echo ${CI_JOB_NAME} | awk -F-- '{print $2}')
    - export PARAM=$(echo ${CI_JOB_NAME} | awk -F-- '{print $3}')
    - export NODE_NUM=$(echo ${PARAM} | awk -Fx '{print $1}')
    - export GPU_NUM=$(echo ${PARAM} | awk -Fx '{print $2}')
    - export BZ_PER_GPU=$(echo ${PARAM} | awk -Fx '{print $3}')
    - export MIXED_PRECISION=$(echo ${PARAM} | awk -Fx '{print $4}')
    - export DGXNNODES=${NODE_NUM}
    - export GPFSFOLDER=$LOGDIR/train_benchmark--${BENCHMARK}--${NODE_NUM}x${GPU_NUM}x${BZ_PER_GPU}x${MIXED_PRECISION}
  variables:
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DATASET_NEW_CRITEO_SELENE}:${NEW_CRITEO_MOUNT},/raid:/raid
    SLURM_ACCOUNT: devtech
    WALLTIME: "00:15:00"
    TEST_CMD: ./ci/benchmark/train_benchmark/run.sub
  rules:
    - if: $NIGHTLY == "1"
      when: manual
    - when: never

collect_benchmark_result:
  extends: .selene_luna_job
  stage: post_test
  variables:
    GPFSFOLDER: $LOGDIR/collect_benchmark_result
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: $LOGDIR:/logs
    SLURM_ACCOUNT: devtech
    WALLTIME: "00:15:00"
    TEST_CMD: ./ci/post_test/collect_benchmark.sub
  rules:
    - if: $NIGHTLY == "1"
      when: manual
    - when: never
